{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmmO7b1DNcss"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/bankira-rahul-is-iitian/Project_ML.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Project_ML/cleaned_last.csv\")\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "ys7aQjYQNsbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "jgeO2sFCNsVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"IS_FRAUD\"].value_counts())"
      ],
      "metadata": {
        "id": "9g6NMud6NsSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['IS_FRAUD'].value_counts())\n"
      ],
      "metadata": {
        "id": "fu0b-9B8VOz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into majority and minority\n",
        "majority = df[df['IS_FRAUD'] == 0]\n",
        "minority = df[df['IS_FRAUD'] == 1]\n",
        "\n",
        "print(\"Majority class:\", len(majority))\n",
        "print(\"Minority class:\", len(minority))\n"
      ],
      "metadata": {
        "id": "SVQ9-4FcVOwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_majority = len(majority)\n",
        "n_minority = len(minority)\n",
        "minority_oversampled = minority.sample(n=n_majority, replace=True, random_state=42)\n",
        "df_oversampled = pd.concat([majority, minority_oversampled])\n",
        "df_oversampled = df_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(df_oversampled['IS_FRAUD'].value_counts())\n"
      ],
      "metadata": {
        "id": "dk2jDk2bVOt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_oversampled.info()"
      ],
      "metadata": {
        "id": "LacYRHg1Wj62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.countplot(x='IS_FRAUD', data=df_oversampled, palette='Set2')\n",
        "plt.title(\"Class Distribution After Oversampling\")\n",
        "plt.xlabel(\"IS_FRAUD (0=No, 1=Yes)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sLui4nq0XFbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sk=df_oversampled"
      ],
      "metadata": {
        "id": "xmTsQxwqbD6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNNClassifier:\n",
        "    \"\"\"k-NN Classifier with multiple distance metrics and weighting options\"\"\"\n",
        "\n",
        "    def __init__(self, distance_metric='euclidean', weighted=False):\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "        self.distance_metric = distance_metric\n",
        "        self.weighted = weighted\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"Store training data\"\"\"\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def _euclidean_distance(self, x1, x2):\n",
        "        \"\"\"Compute Euclidean distance\"\"\"\n",
        "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "\n",
        "    def _manhattan_distance(self, x1, x2):\n",
        "        \"\"\"Compute Manhattan distance\"\"\"\n",
        "        return np.sum(np.abs(x1 - x2))\n",
        "\n",
        "    def _compute_distance(self, x1, x2):\n",
        "        \"\"\"Compute distance based on selected metric\"\"\"\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return self._euclidean_distance(x1, x2)\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return self._manhattan_distance(x1, x2)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown distance metric\")\n",
        "\n",
        "    def predict(self, X_test, k=3):\n",
        "        \"\"\"Predict class labels for test samples\"\"\"\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            distances = np.array([self._compute_distance(x, x_train)\n",
        "                                for x_train in self.X_train])\n",
        "            neighbors_idx = np.argsort(distances)[:k]\n",
        "            neighbor_labels = self.y_train[neighbors_idx]\n",
        "            neighbor_distances = distances[neighbors_idx]\n",
        "\n",
        "            if self.weighted:\n",
        "                # Distance-weighted voting\n",
        "                epsilon = 1e-5\n",
        "                weights = 1 / (neighbor_distances + epsilon)\n",
        "                votes = {}\n",
        "                for w, lbl in zip(weights, neighbor_labels):\n",
        "                    lbl = int(lbl)\n",
        "                    votes[lbl] = votes.get(lbl, 0) + w\n",
        "                predicted = max(votes, key=votes.get)\n",
        "            else:\n",
        "                # Majority voting\n",
        "                counts = np.bincount(neighbor_labels.astype(int))\n",
        "                if len(np.unique(neighbor_labels)) == 2 and counts[0] == counts[1]:\n",
        "                    # Tie-breaking: choose class with smaller mean distance\n",
        "                    mean_dist_0 = np.mean(neighbor_distances[neighbor_labels == 0])\n",
        "                    mean_dist_1 = np.mean(neighbor_distances[neighbor_labels == 1])\n",
        "                    predicted = 0 if mean_dist_0 < mean_dist_1 else 1\n",
        "                else:\n",
        "                    predicted = np.argmax(counts)\n",
        "\n",
        "            predictions.append(predicted)\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def get_neighbors(self, x, k=3):\n",
        "        \"\"\"Get k nearest neighbors for a point\"\"\"\n",
        "        distances = np.array([self._compute_distance(x, x_train)\n",
        "                            for x_train in self.X_train])\n",
        "        neighbors_idx = np.argsort(distances)[:k]\n",
        "        return neighbors_idx, distances[neighbors_idx]"
      ],
      "metadata": {
        "id": "onX8oMHEYmCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "target_col = 'IS_FRAUD'\n",
        "X = sk.drop(columns=[target_col])\n",
        "y = sk[target_col].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X.values, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "knn = KNNClassifier(distance_metric='euclidean', weighted=False)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test, k=5)\n",
        "\n",
        "#Evaluate\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"KNN Classifier Results:\")\n",
        "print(f\"Accuracy:  {acc:.3f}\")\n",
        "print(f\"Precision: {prec:.3f}\")\n",
        "print(f\"Recall:    {rec:.3f}\")\n",
        "print(f\"F1 Score:  {f1:.3f}\")\n"
      ],
      "metadata": {
        "id": "ZUJEAR-OXPXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "BDpTex3nZZKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-FOLD Validation"
      ],
      "metadata": {
        "id": "dbvaicD3hQ4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def find_optimal_k(X_train, y_train, k_range=range(1, 21), cv_folds=5):\n",
        "    cv_scores = []\n",
        "    best_score = 0\n",
        "    best_k = 1\n",
        "\n",
        "    print(\"Performing Cross-Validation for Optimal k...\")\n",
        "    print(\"k\\tMean F1-Score\\tStd Dev\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    for k in k_range:\n",
        "        knn_cv = KNNClassifier(distance_metric='euclidean', weighted=False)\n",
        "        def knn_predict(X_test_fold):\n",
        "            return knn_cv.predict(X_test_fold, k=k)\n",
        "        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "        fold_scores = []\n",
        "\n",
        "        for train_idx, val_idx in skf.split(X_train, y_train):\n",
        "\n",
        "            X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
        "            y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
        "            knn_cv.fit(X_fold_train, y_fold_train)\n",
        "            y_fold_pred = knn_cv.predict(X_fold_val, k=k)\n",
        "            fold_f1 = f1_score(y_fold_val, y_fold_pred)\n",
        "            fold_scores.append(fold_f1)\n",
        "\n",
        "        mean_score = np.mean(fold_scores)\n",
        "        std_score = np.std(fold_scores)\n",
        "        cv_scores.append(mean_score)\n",
        "\n",
        "        print(f\"{k}\\t{mean_score:.4f}\\t\\t{std_score:.4f}\")\n",
        "        if mean_score > best_score:\n",
        "            best_score = mean_score\n",
        "            best_k = k\n",
        "\n",
        "    return best_k, cv_scores, k_range\n",
        "best_k, cv_scores, k_range = find_optimal_k(X_train, y_train, k_range=range(1, 26), cv_folds=5)\n",
        "\n",
        "print(f\"\\nOptimal k: {best_k} with F1-Score: {cv_scores[best_k-1]:.4f}\")"
      ],
      "metadata": {
        "id": "RkE2lXJ5qC1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, cv_scores, marker='o', linestyle='-', color='b', label='CV F1-Score')\n",
        "plt.axvline(x=best_k, color='r', linestyle='--', alpha=0.7, label=f'Optimal k = {best_k}')\n",
        "plt.xlabel('k Value')\n",
        "plt.ylabel('Cross-Validation F1-Score')\n",
        "plt.title('Finding Optimal k for KNN Classifier')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d5gP6FIzqCxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_knn_configurations(X_train, y_train, X_test, y_test, k_values=[3, 5, 7, 9]):\n",
        "    configurations = [\n",
        "        {'distance_metric': 'euclidean', 'weighted': False, 'name': 'Euclidean + Majority'},\n",
        "        {'distance_metric': 'euclidean', 'weighted': True, 'name': 'Euclidean + Weighted'},\n",
        "        {'distance_metric': 'manhattan', 'weighted': False, 'name': 'Manhattan + Majority'},\n",
        "        {'distance_metric': 'manhattan', 'weighted': True, 'name': 'Manhattan + Weighted'}\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    print(\"Comparing KNN Configurations...\")\n",
        "    print(\"Configuration\\t\\t\\tk\\tAccuracy\\tPrecision\\tRecall\\tF1-Score\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for config in configurations:\n",
        "        for k in k_values:\n",
        "            # Train and evaluate\n",
        "            knn = KNNClassifier(\n",
        "                distance_metric=config['distance_metric'],\n",
        "                weighted=config['weighted']\n",
        "            )\n",
        "            knn.fit(X_train, y_train)\n",
        "            y_pred = knn.predict(X_test, k=k)\n",
        "\n",
        "            # Calculate metrics\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "            prec = precision_score(y_test, y_pred)\n",
        "            rec = recall_score(y_test, y_pred)\n",
        "            f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "            results.append({\n",
        "                'config': config['name'],\n",
        "                'k': k,\n",
        "                'accuracy': acc,\n",
        "                'precision': prec,\n",
        "                'recall': rec,\n",
        "                'f1_score': f1\n",
        "            })\n",
        "\n",
        "            print(f\"{config['name']:25} {k}\\t{acc:.4f}\\t\\t{prec:.4f}\\t\\t{rec:.4f}\\t{f1:.4f}\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Compare configurations\n",
        "results_df = compare_knn_configurations(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "JbvoG1MHqCpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_overall = results_df.loc[results_df['f1_score'].idxmax()]\n",
        "\n",
        "print(\"\\nüèÜ BEST OVERALL CONFIGURATION:\")\n",
        "print(f\"Configuration: {best_overall['config']}\")\n",
        "print(f\"k value: {best_overall['k']}\")\n",
        "print(f\"F1-Score: {best_overall['f1_score']:.4f}\")\n",
        "print(f\"Accuracy: {best_overall['accuracy']:.4f}\")\n",
        "print(f\"Precision: {best_overall['precision']:.4f}\")\n",
        "print(f\"Recall: {best_overall['recall']:.4f}\")"
      ],
      "metadata": {
        "id": "MCKIORCRqWgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFINAL EVALUATION WITH OPTIMAL PARAMETERS:\")\n",
        "final_knn = KNNClassifier(distance_metric='euclidean', weighted=True)\n",
        "final_knn.fit(X_train, y_train)\n",
        "y_pred_final = final_knn.predict(X_test, k=best_k)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(f\"Using k={best_k}, Euclidean distance with weighted voting\")\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_final))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "cm = confusion_matrix(y_test, y_pred_final)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix - Final KNN Model')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "final_accuracy = accuracy_score(y_test, y_pred_final)\n",
        "final_precision = precision_score(y_test, y_pred_final)\n",
        "final_recall = recall_score(y_test, y_pred_final)\n",
        "final_f1 = f1_score(y_test, y_pred_final)\n",
        "\n",
        "print(f\"\\\\n Final Model Performance:\")\n",
        "print(f\"Accuracy:  {final_accuracy:.3f}\")\n",
        "print(f\"Precision: {final_precision:.3f}\")\n",
        "print(f\"Recall:    {final_recall:.3f}\")\n",
        "print(f\"F1-Score:  {final_f1:.3f}\")"
      ],
      "metadata": {
        "id": "OFFiE2ayqWdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BAGGING"
      ],
      "metadata": {
        "id": "1hwxafFpt2wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KNNBaggingClassifier:\n",
        "\n",
        "    def __init__(self, n_estimators=10, k=5, distance_metric='euclidean', weighted=False,\n",
        "                 max_samples=1.0, random_state=42):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "        self.weighted = weighted\n",
        "        self.max_samples = max_samples\n",
        "        self.random_state = random_state\n",
        "        self.estimators_ = []\n",
        "        self.sample_indices_ = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        np.random.seed(self.random_state)\n",
        "        n_samples = X.shape[0]\n",
        "        n_bootstrap = int(n_samples * self.max_samples)\n",
        "\n",
        "        self.estimators_ = []\n",
        "        self.sample_indices_ = []\n",
        "\n",
        "        print(f\"Training {self.n_estimators} KNN estimators with bagging...\")\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            bootstrap_indices = np.random.choice(n_samples, size=n_bootstrap, replace=True)\n",
        "            X_bootstrap = X[bootstrap_indices]\n",
        "            y_bootstrap = y[bootstrap_indices]\n",
        "            knn = KNNClassifier(distance_metric=self.distance_metric, weighted=self.weighted)\n",
        "            knn.fit(X_bootstrap, y_bootstrap)\n",
        "\n",
        "            self.estimators_.append(knn)\n",
        "            self.sample_indices_.append(bootstrap_indices)\n",
        "\n",
        "            if (i + 1) % 5 == 0 or (i + 1) == self.n_estimators:\n",
        "                print(f\"  Trained estimator {i + 1}/{self.n_estimators}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions using majority voting from all estimators\"\"\"\n",
        "        all_predictions = []\n",
        "\n",
        "        for i, estimator in enumerate(self.estimators_):\n",
        "            predictions = estimator.predict(X, k=self.k)\n",
        "            all_predictions.append(predictions)\n",
        "        all_predictions = np.array(all_predictions)\n",
        "\n",
        "        # Majority voting\n",
        "        final_predictions = []\n",
        "        for sample_idx in range(X.shape[0]):\n",
        "            votes = all_predictions[:, sample_idx]\n",
        "            majority_vote = np.bincount(votes.astype(int)).argmax()\n",
        "            final_predictions.append(majority_vote)\n",
        "\n",
        "        return np.array(final_predictions)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Predict class probabilities (soft voting)\"\"\"\n",
        "        all_predictions = []\n",
        "\n",
        "        for estimator in self.estimators_:\n",
        "            predictions = estimator.predict(X, k=self.k)\n",
        "            all_predictions.append(predictions)\n",
        "\n",
        "        all_predictions = np.array(all_predictions)\n",
        "        probabilities = []\n",
        "        for sample_idx in range(X.shape[0]):\n",
        "            votes = all_predictions[:, sample_idx]\n",
        "            class_0_prob = np.sum(votes == 0) / self.n_estimators\n",
        "            class_1_prob = np.sum(votes == 1) / self.n_estimators\n",
        "            probabilities.append([class_0_prob, class_1_prob])\n",
        "\n",
        "        return np.array(probabilities)"
      ],
      "metadata": {
        "id": "PzMeMPQ7t5YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing Bagging KNN Classifier...\")\n",
        "\n",
        "# Initialize bagging classifier\n",
        "bagging_knn = KNNBaggingClassifier(\n",
        "    n_estimators=20,\n",
        "    k=5,\n",
        "    distance_metric='euclidean',\n",
        "    weighted=False,\n",
        "    max_samples=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "bagging_knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_bagging = bagging_knn.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "acc_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "prec_bagging = precision_score(y_test, y_pred_bagging)\n",
        "rec_bagging = recall_score(y_test, y_pred_bagging)\n",
        "f1_bagging = f1_score(y_test, y_pred_bagging)\n",
        "\n",
        "print(\"\\nBagging KNN Results:\")\n",
        "print(f\"Accuracy:  {acc_bagging:.3f}\")\n",
        "print(f\"Precision: {prec_bagging:.3f}\")\n",
        "print(f\"Recall:    {rec_bagging:.3f}\")\n",
        "print(f\"F1-Score:  {f1_bagging:.3f}\")"
      ],
      "metadata": {
        "id": "HsiqMuAet6Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare with single KNN\n",
        "print(\" Comparison: Single KNN vs Bagging KNN\")\n",
        "\n",
        "# Single KNN (for comparison)\n",
        "single_knn = KNNClassifier(distance_metric='euclidean', weighted=False)\n",
        "single_knn.fit(X_train, y_train)\n",
        "y_pred_single = single_knn.predict(X_test, k=5)\n",
        "\n",
        "acc_single = accuracy_score(y_test, y_pred_single)\n",
        "prec_single = precision_score(y_test, y_pred_single)\n",
        "rec_single = recall_score(y_test, y_pred_single)\n",
        "f1_single = f1_score(y_test, y_pred_single)\n",
        "\n",
        "print(\"\\nSingle KNN:\")\n",
        "print(f\"Accuracy:  {acc_single:.3f}\")\n",
        "print(f\"Precision: {prec_single:.3f}\")\n",
        "print(f\"Recall:    {rec_single:.3f}\")\n",
        "print(f\"F1-Score:  {f1_single:.3f}\")\n",
        "\n",
        "print(\"\\nBagging KNN:\")\n",
        "print(f\"Accuracy:  {acc_bagging:.3f}\")\n",
        "print(f\"Precision: {prec_bagging:.3f}\")\n",
        "print(f\"Recall:    {rec_bagging:.3f}\")\n",
        "print(f\"F1-Score:  {f1_bagging:.3f}\")\n",
        "\n",
        "# Calculate improvement\n",
        "improvement = ((f1_bagging - f1_single) / f1_single) * 100\n",
        "print(f\"\\nF1-Score Improvement: {improvement:+.2f}%\")"
      ],
      "metadata": {
        "id": "vndrPlb8t6OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for Bagging KNN\n",
        "def tune_bagging_knn(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"Find optimal parameters for Bagging KNN\"\"\"\n",
        "\n",
        "    param_combinations = [\n",
        "        {'n_estimators': 10, 'k': 3, 'max_samples': 0.7},\n",
        "        {'n_estimators': 20, 'k': 5, 'max_samples': 0.8},\n",
        "        {'n_estimators': 30, 'k': 7, 'max_samples': 0.9},\n",
        "        {'n_estimators': 20, 'k': 5, 'max_samples': 1.0},\n",
        "        {'n_estimators': 15, 'k': 5, 'max_samples': 0.8, 'weighted': True},\n",
        "    ]\n",
        "\n",
        "    best_score = 0\n",
        "    best_params = None\n",
        "    results = []\n",
        "\n",
        "    print(\"Tuning Bagging KNN Hyperparameters...\")\n",
        "    print(\"n_estimators\\tk\\tmax_samples\\tweighted\\tF1-Score\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for params in param_combinations:\n",
        "        bagging_knn = KNNBaggingClassifier(\n",
        "            n_estimators=params['n_estimators'],\n",
        "            k=params['k'],\n",
        "            max_samples=params['max_samples'],\n",
        "            weighted=params.get('weighted', False),\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Use a smaller subset for faster tuning (optional)\n",
        "        if X_train.shape[0] > 10000:\n",
        "            # Sample for faster computation\n",
        "            indices = np.random.choice(X_train.shape[0], 5000, replace=False)\n",
        "            X_tune = X_train[indices]\n",
        "            y_tune = y_train[indices]\n",
        "        else:\n",
        "            X_tune = X_train\n",
        "            y_tune = y_train\n",
        "\n",
        "        bagging_knn.fit(X_tune, y_tune)\n",
        "        y_pred = bagging_knn.predict(X_test)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        results.append({\n",
        "            'n_estimators': params['n_estimators'],\n",
        "            'k': params['k'],\n",
        "            'max_samples': params['max_samples'],\n",
        "            'weighted': params.get('weighted', False),\n",
        "            'f1_score': f1\n",
        "        })\n",
        "\n",
        "        print(f\"{params['n_estimators']}\\t\\t{params['k']}\\t{params['max_samples']}\\t\\t{params.get('weighted', False)}\\t\\t{f1:.4f}\")\n",
        "\n",
        "        if f1 > best_score:\n",
        "            best_score = f1\n",
        "            best_params = params\n",
        "\n",
        "    return best_params, best_score, results\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "best_params, best_score, tuning_results = tune_bagging_knn(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(f\"\\nüèÜ Best Parameters: {best_params}\")\n",
        "print(f\"üéØ Best F1-Score: {best_score:.4f}\")"
      ],
      "metadata": {
        "id": "fUQrYtUot6Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t8VRb30cuWtB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}