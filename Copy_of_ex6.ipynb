{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmmO7b1DNcss"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/bankira-rahul-is-iitian/Project_ML.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Project_ML/cleaned_fraud_dataset.csv\")\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "ys7aQjYQNsbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=[\"month\",\"year\"], inplace=True)"
      ],
      "metadata": {
        "id": "YoEnES3eNsXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "jgeO2sFCNsVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"IS_FRAUD\"].value_counts())"
      ],
      "metadata": {
        "id": "9g6NMud6NsSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['IS_FRAUD'].value_counts())\n"
      ],
      "metadata": {
        "id": "fu0b-9B8VOz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into majority and minority\n",
        "majority = df[df['IS_FRAUD'] == 0]\n",
        "minority = df[df['IS_FRAUD'] == 1]\n",
        "\n",
        "print(\"Majority class:\", len(majority))\n",
        "print(\"Minority class:\", len(minority))\n"
      ],
      "metadata": {
        "id": "SVQ9-4FcVOwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downsample majority class to match minority size\n",
        "majority_downsampled = majority.sample(n=len(minority), random_state=42)\n",
        "\n",
        "# Combine both classes\n",
        "df_downsampled = pd.concat([majority_downsampled, minority])\n",
        "\n",
        "# Shuffle the dataset\n",
        "df_downsampled = df_downsampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Check new distribution\n",
        "print(df_downsampled['IS_FRAUD'].value_counts())\n"
      ],
      "metadata": {
        "id": "mmcuRFM_XrPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.countplot(x='IS_FRAUD', data=df_downsampled, palette='Set2')\n",
        "plt.title(\"Class Distribution After Oversampling\")\n",
        "plt.xlabel(\"IS_FRAUD (0=No, 1=Yes)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sLui4nq0XFbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_downsampled"
      ],
      "metadata": {
        "id": "6Ul6wH68Zo6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dk=df_downsampled"
      ],
      "metadata": {
        "id": "yGqJ6HWKaiO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dk"
      ],
      "metadata": {
        "id": "szCBIxXaapCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNNClassifier:\n",
        "    \"\"\"k-NN Classifier with multiple distance metrics and weighting options\"\"\"\n",
        "\n",
        "    def __init__(self, distance_metric='euclidean', weighted=False):\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "        self.distance_metric = distance_metric\n",
        "        self.weighted = weighted\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"Store training data\"\"\"\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def _euclidean_distance(self, x1, x2):\n",
        "        \"\"\"Compute Euclidean distance\"\"\"\n",
        "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "\n",
        "    def _manhattan_distance(self, x1, x2):\n",
        "        \"\"\"Compute Manhattan distance\"\"\"\n",
        "        return np.sum(np.abs(x1 - x2))\n",
        "\n",
        "    def _compute_distance(self, x1, x2):\n",
        "        \"\"\"Compute distance based on selected metric\"\"\"\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return self._euclidean_distance(x1, x2)\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return self._manhattan_distance(x1, x2)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown distance metric\")\n",
        "\n",
        "    def predict(self, X_test, k=3):\n",
        "        \"\"\"Predict class labels for test samples\"\"\"\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            distances = np.array([self._compute_distance(x, x_train)\n",
        "                                for x_train in self.X_train])\n",
        "            neighbors_idx = np.argsort(distances)[:k]\n",
        "            neighbor_labels = self.y_train[neighbors_idx]\n",
        "            neighbor_distances = distances[neighbors_idx]\n",
        "\n",
        "            if self.weighted:\n",
        "                # Distance-weighted voting\n",
        "                epsilon = 1e-5\n",
        "                weights = 1 / (neighbor_distances + epsilon)\n",
        "                votes = {}\n",
        "                for w, lbl in zip(weights, neighbor_labels):\n",
        "                    lbl = int(lbl)\n",
        "                    votes[lbl] = votes.get(lbl, 0) + w\n",
        "                predicted = max(votes, key=votes.get)\n",
        "            else:\n",
        "                # Majority voting\n",
        "                counts = np.bincount(neighbor_labels.astype(int))\n",
        "                if len(np.unique(neighbor_labels)) == 2 and counts[0] == counts[1]:\n",
        "                    # Tie-breaking: choose class with smaller mean distance\n",
        "                    mean_dist_0 = np.mean(neighbor_distances[neighbor_labels == 0])\n",
        "                    mean_dist_1 = np.mean(neighbor_distances[neighbor_labels == 1])\n",
        "                    predicted = 0 if mean_dist_0 < mean_dist_1 else 1\n",
        "                else:\n",
        "                    predicted = np.argmax(counts)\n",
        "\n",
        "            predictions.append(predicted)\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def get_neighbors(self, x, k=3):\n",
        "        \"\"\"Get k nearest neighbors for a point\"\"\"\n",
        "        distances = np.array([self._compute_distance(x, x_train)\n",
        "                            for x_train in self.X_train])\n",
        "        neighbors_idx = np.argsort(distances)[:k]\n",
        "        return neighbors_idx, distances[neighbors_idx]"
      ],
      "metadata": {
        "id": "Kz2ZKfD6Y-7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6duEoqESY-39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# Ensure target column is named correctly\n",
        "target_col = 'IS_FRAUD'  # change if different\n",
        "X = dk.drop(columns=[target_col])\n",
        "y = dk[target_col].values\n",
        "\n",
        "# âœ… Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X.values, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# âœ… Standardize features (important for KNN)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# âœ… Import your KNN class (paste the definition here if not imported already)\n",
        "# from your_file import KNNClassifier  # not needed if class is already defined\n",
        "\n",
        "# Instantiate and train\n",
        "knn = KNNClassifier(distance_metric='euclidean', weighted=False)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# âœ… Predict\n",
        "y_pred = knn.predict(X_test, k=5)\n",
        "\n",
        "# âœ… Evaluate\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"ðŸ“Š KNN Classifier (Custom Implementation) Results:\")\n",
        "print(f\"Accuracy:  {acc:.3f}\")\n",
        "print(f\"Precision: {prec:.3f}\")\n",
        "print(f\"Recall:    {rec:.3f}\")\n",
        "print(f\"F1 Score:  {f1:.3f}\")\n"
      ],
      "metadata": {
        "id": "ZUJEAR-OXPXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "v41pcNFaZUry"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}